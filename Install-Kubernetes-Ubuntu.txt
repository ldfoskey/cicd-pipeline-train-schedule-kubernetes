 /  _____||   ____||   ____||  |/  / |  |  |  | |   ____|   /   \     |       \
|  |  __  |  |__   |  |__   |  '  /  |  |__|  | |  |__     /  ^  \    |  .--.  |
|  | |_ | |   __|  |   __|  |    <   |   __   | |   __|   /  /_\  \   |  |  |  |
|  |__| | |  |____ |  |____ |  .  \  |  |  |  | |  |____ /  _____  \  |  '--'  |
 \______| |_______||_______||__|\__\ |__|  |__| |_______/__/     \__\ |_______/

KUBERNETES 1.26
CONTAINERD 1.6.16
UBUNTU 22.04

### ALL: 

sudo -s (use in training environment only)

printf "\n192.168.15.93 k8s-control\n192.168.15.94 k8s-2\n\n" >> /etc/hosts
	-Or update /etc/hosts manually with all IPs from list at bottom of this doc.
	-sudo vim /etc/hosts 

printf "overlay\nbr_netfilter\n" >> /etc/modules-load.d/containerd.conf

modprobe overlay (not needed if rebooting)
modprobe br_netfilter (not needed if rebooting)

printf "net.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\n" >> /etc/sysctl.d/99-kubernetes-cri.conf

cat /etc/sysctl.d/99-kubernetes-cri.conf

sysctl --system (not needed if rebooting)

ll

wget https://github.com/containerd/containerd/releases/download/v1.6.16/containerd-1.6.16-linux-amd64.tar.gz -P /tmp/

tar Cxzvf /usr/local /tmp/containerd-1.6.16-linux-amd64.tar.gz

wget https://raw.githubusercontent.com/containerd/containerd/main/containerd.service -P /etc/systemd/system/

cat /etc/systemd/system/containerd.service

systemctl daemon-reload
systemctl enable --now containerd

wget https://github.com/opencontainers/runc/releases/download/v1.1.4/runc.amd64 -P /tmp/

install -m 755 /tmp/runc.amd64 /usr/local/sbin/runc

wget https://github.com/containernetworking/plugins/releases/download/v1.2.0/cni-plugins-linux-amd64-v1.2.0.tgz -P /tmp/

mkdir -p /opt/cni/bin

tar Cxzvf /opt/cni/bin /tmp/cni-plugins-linux-amd64-v1.2.0.tgz

mkdir -p /etc/containerd

containerd config default | tee /etc/containerd/config.toml <<<<<<<<<<
manually edit and change systemdCgroup to true

vim /etc/containerd/config.toml <<<<<<<<<<< change systemdCgroup to true

systemctl restart containerd

swapoff -a <<<<<<<< just disable it in /etc/fstab instead
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab <<<<<<<< disable even after reboot
vim /etc/sysctl.conf  <<<<<<<<  add vm.swappiness=0 to end of file

apt-get update
apt-get install -y apt-transport-https ca-certificates curl

# curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg
# https://packages.cloud.google.com/apt/doc/apt-key.gpg <<<<<<errored

curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpg

echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | tee /etc/apt/sources.list.d/kubernetes.list

apt-get update
 
reboot

sudo -s (use in training environment only)

swapoff -a

# check swap config, ensure swap is 0
free -m

sudo ufw status
sudo ufw allow 6443 or sudo ufw disable

apt-get install -y kubelet=1.27.2-00 kubeadm=1.27.2-00 kubectl=1.27.2-00
apt-mark hold kubelet kubeadm kubectl


### ONLY ON CONTROL NODE .. control plane install:
kubeadm init --pod-network-cidr 10.244.0.0/16 --kubernetes-version 1.27.2 --node-name bea4823eca1c.mylabserver.com

https://www.thinkcode.se/blog/2019/02/20/kubernetes-service-node-port-range
	- vim  /etc/kubernetes/manifests/kube-apiserver.yaml
	- --service-node-port-range=8000-31274 (add it just below "--service-cluster-ip-range" entry)

# vim kube-config.yml:

#	apiVersion: kubeadm.k8s.io/v1beta3
#	kind: ClusterConfiguration
#	networking:
#  		serviceSubnet: "10.96.0.0/16"
#  		podSubnet: "10.244.0.0/24"
#  		dnsDomain: "cluster.local"
#	kubernetesVersion: "v1.27.2"
#	apiServer:
#  	  extraArgs:
#    		service-node-port-range: 8000-31274

# kubeadm init --config kube-config.yml

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config


# add Calico 3.25 CNI 
### https://docs.tigera.io/calico/3.25/getting-started/kubernetes/quickstart
# kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/tigera-operator.yaml

# or

kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# wget https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/custom-resources.yaml

# - <<<<<< edit the CIDR for pods if its custom by changing cidr in  # file to 10.10.0.0/16

# kubectl apply -f custom-resources.yaml

kubectl get nodes or kubectl get pods --all-namespaces

# get worker node commands to run to join additional nodes into cluster
kubeadm token create --print-join-command


## ONLY ON WORKER nodes
Run the command from the token create output above

13.52.75.135   bea4823eca1c.mylabserver.com
54.241.224.107 bea4823eca2c.mylabserver.com
54.151.9.173   bea4823eca3c.mylabserver.com

172.31.105.110 bea4823eca1c.mylabserver.com
172.31.107.66  bea4823eca2c.mylabserver.com
172.31.96.100  bea4823eca3c.mylabserver.com


